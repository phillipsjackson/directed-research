# Weekly Summary:

## Previous week take home message:
- fixed mini project 2 so that it runs smoothly in the command prompt
- understand briefly how neural networks work
- try to understand issues with visual studio, failed.

## What was done this week
- Played around with neural network in ann_expl.py, understood more of what weights mean and and how hyperparameters effect weights. 
- Completed mini project 2, not fully correctly but understood more of neural network

## Scientific project, advancement:
- More basic research on how implementing code works in Assetto Corsa, spent more time understanding the neural network as it will likely be used to simulate driver behavior in the model.

# TODO for next week:

- Mini project 2, epxloration:
  + Explore the _hyperparameters_ eta, n_iter, size of hidden layer and the percentage of data use for the test set. Explain each one and illustrte how changing them changes the accuracy of the results
  + add figures using \includegraphics
  + reference algorithm and figure using \label and \ref
  + optional: explore the weight: using the function show_weight, see what the weigh are ad try to see to which input/output they correspond (you can try to draw a diagram, you can use tikz again for that if you want, the LLM can help you for you).
- General organisation: try to follow IMRAD : https://link.springer.com/article/10.1007/s10980-011-9674-3
- Biblio: start looking into how to do a bibliography in Latex, export Mendeley in bibtex format


